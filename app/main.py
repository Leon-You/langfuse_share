# ------------------------ FastAPI é€»è¾‘ ------------------------

from fastapi import FastAPI
from pydantic import BaseModel, Field

# å®šä¹‰è¯·æ±‚ä½“æ¨¡å‹
class ChatRequest(BaseModel):
    user_id: str = Field(default="test_user_id", description="ç”¨æˆ·ID")
    message: str = Field(default="ä½ å¥½", description="ç”¨æˆ·æ¶ˆæ¯")

# å®šä¹‰å“åº”ä½“æ¨¡å‹
class ChatResponse(BaseModel):
    reply: str = Field(..., description="æœºå™¨äººå›å¤")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="Simple Chatbot API", description="ä¸€ä¸ªç®€å•çš„å¯¹è¯æœºå™¨äººæ¥å£ç¤ºä¾‹")

# å®šä¹‰ä¸€ä¸ª POST æ¥å£
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    ä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººæ¥å£ã€‚
    """
    reply = await chatbot_wrapper(request.user_id, request.message)
    
    return ChatResponse(reply=reply)

# ------------------------ èŠå¤©æœºå™¨äººé€»è¾‘ ------------------------
from langfuse.openai import openai
from langfuse import observe, get_client, propagate_attributes
from dotenv import load_dotenv
import time
# åŠ è½½langfuseéœ€è¦çš„ç¯å¢ƒå˜é‡
load_dotenv("../.env")
# è·å–Langfuseå®¢æˆ·ç«¯
client = get_client()

@observe(name="èŠå¤©æœºå™¨äººåŒ…è£…å™¨")
async def chatbot_wrapper(user_id: str, message: str):
    with propagate_attributes(user_id=user_id):
        return await chatbot(message)

@observe(name="èŠå¤©æœºå™¨äºº")
async def chatbot(message: str):
    """
    æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººå›å¤ã€‚
    """
    # åˆ›å»ºä¸€ä¸ªå†…éƒ¨spanï¼Œç”¨äºè®°å½•å†…éƒ¨å¤„ç†æ—¶é—´
    span = client.start_span(name="ç¬¬ä¸€ä¸ªspan")
    time.sleep(0.3) # æ¨¡æ‹Ÿå†…éƒ¨å¤„ç†æ—¶é—´
    span.update(output=f"ç¬¬ä¸€ä¸ªspanå¤„ç†å®Œæˆ: {message}")
    span.end()

    # åˆ›å»ºä¸€ä¸ªç”Ÿæˆspanï¼Œç”¨äºè®°å½•ç”Ÿæˆè¿‡ç¨‹ï¼ˆPython SDKï¼‰
    generation = client.start_generation(
                name="æ¨¡å‹ç”Ÿæˆ",
                model="xx-model",
                input=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè™šæ‹ŸåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”ã€‚"},
                    {"role": "user", "content": message}
                    ],
                metadata={"tag": "chatbot-è°ƒç”¨è®°å½•"},
            )
    time.sleep(0.5) # æ¨¡æ‹Ÿç”Ÿæˆæ—¶é—´
    if "ä½ å¥½" in message:
        reply = "ä½ å¥½å‘€ï¼Œæˆ‘æ˜¯ä½ çš„è™šæ‹ŸåŠ©æ‰‹ ğŸ˜Š"
    elif "å¤©æ°”" in message:
        reply = "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå†™ä»£ç ã€‚"
    else:
        reply = f"ä½ è¯´çš„æ˜¯ï¼š{message}ï¼Ÿè¿™ä¸ªæˆ‘è¿˜ä¸å¤ªæ‡‚ï½"
    generation.update(output=[{"role": "assistant", "content": reply}])
    generation.end()

    # åˆ›å»ºä¸€ä¸ªç”Ÿæˆspanï¼Œç”¨äºè®°å½•ç”Ÿæˆè¿‡ç¨‹ï¼ˆOpenAI SDKï¼‰
    # completion = openai.chat.completions.create(
    #     name="æ¨¡å‹ç”Ÿæˆ",
    #     model="xx-model",
    #     messages=[
    #         {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè™šæ‹ŸåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”ã€‚"},
    #         {"role": "user", "content": message}],
    # )
    # reply = completion.choices[0].message.content
    # åˆ·æ–°æ‰€æœ‰span
    client.flush()
    return reply
